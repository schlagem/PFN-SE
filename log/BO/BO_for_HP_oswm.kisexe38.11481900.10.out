FOUND eth0 INTERFACE
Worker starting at: 20240507-000354
Using cpu:0 device
init dist
Not using distributed
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 4, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b0e04b80>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'gelu', 'decoder_depth': 6, 'decoder_res_connection': True, 'decoder_type': 'mlp', 'decoder_use_bias': False, 'decoder_width': 64, 'encoder_activation': 'sigmoid', 'encoder_depth': 6, 'encoder_res_connection': True, 'encoder_type': 'mlp', 'encoder_use_bias': False, 'encoder_width': 256, 'env_name': 'NNEnv', 'relu': True, 'sigmoid': True, 'sin': True, 'state_offset': 1.0546243903212726, 'state_scale': 10.72506020562667, 'tanh': True, 'use_bias': True, 'use_dropout': True, 'use_layer_norm': False, 'use_res_connection': False, 'dropout_p': 0.3612684451436706, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized data loader with 100 steps and 4 batch size
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 1, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b0e04b80>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'gelu', 'decoder_depth': 6, 'decoder_res_connection': True, 'decoder_type': 'mlp', 'decoder_use_bias': False, 'decoder_width': 64, 'encoder_activation': 'sigmoid', 'encoder_depth': 6, 'encoder_res_connection': True, 'encoder_type': 'mlp', 'encoder_use_bias': False, 'encoder_width': 256, 'env_name': 'NNEnv', 'relu': True, 'sigmoid': True, 'sin': True, 'state_offset': 1.0546243903212726, 'state_scale': 10.72506020562667, 'tanh': True, 'use_bias': True, 'use_dropout': True, 'use_layer_norm': False, 'use_res_connection': False, 'dropout_p': 0.3612684451436706, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized decoder for standard with (<class 'owsm_worker.mlp_decoder_generator_generator.<locals>.NNDecClass'>, 14)  and nout 14
Using a Transformer with 13.73 M parameters
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 444.68s | mean loss  0.02 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.62,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.68,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 1.56,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.95,-, 0.51,-,-,-,-,-, lr of zeroth group 1.2458333333333336e-05 data time 417.28 step time  1.05 forward time  0.21 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
All batches have NaN in loss. Target NaN False output NaN True
-----------------------------------------------------------------------------------------
Using cpu:0 device
init dist
Not using distributed
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 4, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b37e7b50>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'relu', 'decoder_depth': 3, 'decoder_res_connection': True, 'decoder_type': 'cat', 'decoder_use_bias': True, 'decoder_width': 256, 'encoder_activation': 'gelu', 'encoder_depth': 2, 'encoder_res_connection': False, 'encoder_type': 'cat', 'encoder_use_bias': True, 'encoder_width': 16, 'env_name': 'MomentumEnv', 'relu': False, 'sigmoid': False, 'sin': True, 'state_offset': 3.8751617444603066, 'state_scale': 18.24702076645672, 'tanh': True, 'use_bias': False, 'use_dropout': False, 'use_layer_norm': True, 'use_res_connection': True, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized data loader with 100 steps and 4 batch size
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 1, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b37e7b50>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'relu', 'decoder_depth': 3, 'decoder_res_connection': True, 'decoder_type': 'cat', 'decoder_use_bias': True, 'decoder_width': 256, 'encoder_activation': 'gelu', 'encoder_depth': 2, 'encoder_res_connection': False, 'encoder_type': 'cat', 'encoder_use_bias': True, 'encoder_width': 16, 'env_name': 'MomentumEnv', 'relu': False, 'sigmoid': False, 'sin': True, 'state_offset': 3.8751617444603066, 'state_scale': 18.24702076645672, 'tanh': True, 'use_bias': False, 'use_dropout': False, 'use_layer_norm': True, 'use_res_connection': True, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized decoder for standard with (<class 'owsm_worker.cat_decoder_generator_generator.<locals>.NNCatDecClass'>, 14)  and nout 14
Using a Transformer with 13.29 M parameters
Invalid epoch encountered, skipping The size of tensor a (2688) must match the size of tensor b (1568) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (16992) must match the size of tensor b (9912) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (35040) must match the size of tensor b (20440) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (40896) must match the size of tensor b (23856) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (16128) must match the size of tensor b (9408) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (2592) must match the size of tensor b (1512) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (2592) must match the size of tensor b (1512) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (18624) must match the size of tensor b (10864) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (20352) must match the size of tensor b (11872) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (29472) must match the size of tensor b (17192) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (23616) must match the size of tensor b (13776) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (20640) must match the size of tensor b (12040) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (6816) must match the size of tensor b (3976) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (7488) must match the size of tensor b (4368) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (43680) must match the size of tensor b (25480) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (45216) must match the size of tensor b (26376) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (5376) must match the size of tensor b (3136) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (27648) must match the size of tensor b (16128) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (23328) must match the size of tensor b (13608) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (2496) must match the size of tensor b (1456) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (15744) must match the size of tensor b (9184) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (6240) must match the size of tensor b (3640) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (18912) must match the size of tensor b (11032) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (32352) must match the size of tensor b (18872) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1440) must match the size of tensor b (840) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (17376) must match the size of tensor b (10136) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (16992) must match the size of tensor b (9912) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (9216) must match the size of tensor b (5376) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (10368) must match the size of tensor b (6048) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1920) must match the size of tensor b (1120) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (30624) must match the size of tensor b (17864) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (14880) must match the size of tensor b (8680) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (10656) must match the size of tensor b (6216) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (960) must match the size of tensor b (560) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (8352) must match the size of tensor b (4872) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (28416) must match the size of tensor b (16576) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (23808) must match the size of tensor b (13888) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (2688) must match the size of tensor b (1568) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (47616) must match the size of tensor b (27776) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (16800) must match the size of tensor b (9800) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (39648) must match the size of tensor b (23128) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (14592) must match the size of tensor b (8512) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (22560) must match the size of tensor b (13160) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (34848) must match the size of tensor b (20328) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (2304) must match the size of tensor b (1344) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (26496) must match the size of tensor b (15456) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (10752) must match the size of tensor b (6272) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (2304) must match the size of tensor b (1344) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (14880) must match the size of tensor b (8680) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (35136) must match the size of tensor b (20496) at non-singleton dimension 0...
Using cpu:0 device
init dist
Not using distributed
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 4, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b04fcb80>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'relu', 'decoder_depth': 2, 'decoder_res_connection': False, 'decoder_type': 'cat', 'decoder_use_bias': False, 'decoder_width': 64, 'encoder_activation': 'gelu', 'encoder_depth': 3, 'encoder_res_connection': False, 'encoder_type': 'cat', 'encoder_use_bias': False, 'encoder_width': 256, 'env_name': 'MomentumEnv', 'relu': False, 'sigmoid': False, 'sin': False, 'state_offset': 2.8780347719561763, 'state_scale': 12.232123585664679, 'tanh': False, 'use_bias': True, 'use_dropout': True, 'use_layer_norm': True, 'use_res_connection': True, 'dropout_p': 0.5230493917621944, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized data loader with 100 steps and 4 batch size
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 1, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b04fcb80>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'relu', 'decoder_depth': 2, 'decoder_res_connection': False, 'decoder_type': 'cat', 'decoder_use_bias': False, 'decoder_width': 64, 'encoder_activation': 'gelu', 'encoder_depth': 3, 'encoder_res_connection': False, 'encoder_type': 'cat', 'encoder_use_bias': False, 'encoder_width': 256, 'env_name': 'MomentumEnv', 'relu': False, 'sigmoid': False, 'sin': False, 'state_offset': 2.8780347719561763, 'state_scale': 12.232123585664679, 'tanh': False, 'use_bias': True, 'use_dropout': True, 'use_layer_norm': True, 'use_res_connection': True, 'dropout_p': 0.5230493917621944, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized decoder for standard with (<class 'owsm_worker.cat_decoder_generator_generator.<locals>.NNCatDecClass'>, 14)  and nout 14
Using a Transformer with 13.62 M parameters
Invalid epoch encountered, skipping The size of tensor a (8928) must match the size of tensor b (5208) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (15744) must match the size of tensor b (9184) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (11808) must match the size of tensor b (6888) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1728) must match the size of tensor b (1008) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1920) must match the size of tensor b (1120) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (14880) must match the size of tensor b (8680) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (672) must match the size of tensor b (392) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (30432) must match the size of tensor b (17752) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (11328) must match the size of tensor b (6608) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (384) must match the size of tensor b (224) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (13152) must match the size of tensor b (7672) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (29280) must match the size of tensor b (17080) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (24384) must match the size of tensor b (14224) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (192) must match the size of tensor b (112) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (25248) must match the size of tensor b (14728) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (26112) must match the size of tensor b (15232) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (14496) must match the size of tensor b (8456) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (21984) must match the size of tensor b (12824) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (45696) must match the size of tensor b (26656) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (8736) must match the size of tensor b (5096) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (576) must match the size of tensor b (336) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (48000) must match the size of tensor b (28000) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (4512) must match the size of tensor b (2632) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (12096) must match the size of tensor b (7056) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (4320) must match the size of tensor b (2520) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (31872) must match the size of tensor b (18592) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (25152) must match the size of tensor b (14672) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (15072) must match the size of tensor b (8792) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (25248) must match the size of tensor b (14728) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (35808) must match the size of tensor b (20888) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (26208) must match the size of tensor b (15288) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (14304) must match the size of tensor b (8344) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (4032) must match the size of tensor b (2352) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (38400) must match the size of tensor b (22400) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (36000) must match the size of tensor b (21000) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (480) must match the size of tensor b (280) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (7488) must match the size of tensor b (4368) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1344) must match the size of tensor b (784) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (864) must match the size of tensor b (504) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1536) must match the size of tensor b (896) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (1152) must match the size of tensor b (672) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (192) must match the size of tensor b (112) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (4128) must match the size of tensor b (2408) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (12000) must match the size of tensor b (7000) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (36192) must match the size of tensor b (21112) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (44544) must match the size of tensor b (25984) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (9504) must match the size of tensor b (5544) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (288) must match the size of tensor b (168) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (10752) must match the size of tensor b (6272) at non-singleton dimension 0...
Invalid epoch encountered, skipping The size of tensor a (27840) must match the size of tensor b (16240) at non-singleton dimension 0...
Using cpu:0 device
init dist
Not using distributed
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 4, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b04fd120>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'relu', 'decoder_depth': 1, 'decoder_res_connection': False, 'decoder_type': 'cat', 'decoder_use_bias': True, 'decoder_width': 256, 'encoder_activation': 'sigmoid', 'encoder_depth': 2, 'encoder_res_connection': True, 'encoder_type': 'mlp', 'encoder_use_bias': False, 'encoder_width': 256, 'env_name': 'NNEnv', 'relu': False, 'sigmoid': True, 'sin': False, 'state_offset': 2.602715025451203, 'state_scale': 18.835809053744438, 'tanh': True, 'use_bias': False, 'use_dropout': False, 'use_layer_norm': False, 'use_res_connection': False, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized data loader with 100 steps and 4 batch size
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 1, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x70e2b04fd120>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'decoder_activation': 'relu', 'decoder_depth': 1, 'decoder_res_connection': False, 'decoder_type': 'cat', 'decoder_use_bias': True, 'decoder_width': 256, 'encoder_activation': 'sigmoid', 'encoder_depth': 2, 'encoder_res_connection': True, 'encoder_type': 'mlp', 'encoder_use_bias': False, 'encoder_width': 256, 'env_name': 'NNEnv', 'relu': False, 'sigmoid': True, 'sin': False, 'state_offset': 2.602715025451203, 'state_scale': 18.835809053744438, 'tanh': True, 'use_bias': False, 'use_dropout': False, 'use_layer_norm': False, 'use_res_connection': False, 'num_hidden': 1, 'width_hidden': 16, 'test': False}}, 'get_batch_method': <function get_batch at 0x70e2b388f7f0>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized decoder for standard with (<class 'owsm_worker.mlp_decoder_generator_generator.<locals>.NNDecClass'>, 14)  and nout 14
Using a Transformer with 13.35 M parameters
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 394.38s | mean loss  0.56 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.30,-,-,-,-,-,-,-, 0.59,-, 0.38,-,-,-,-,-,-,-,-,-,-,-,-, 0.42,-, 0.53,-, 0.51,-,-,-, 0.56,-, 0.50,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.86,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.37, 0.69,-,-, 1.23,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.33,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.28, 0.40,-, 0.77,-,-,-, 0.61,-,-,-,-,-,-,-,-,-,-,-, 0.48, 0.60,-,-,-, 0.52,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.38,-,-,-,-,-,-,-, 0.74,-,-,-,-, 0.42,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.40,-,-,-,-, 0.67,-, 1.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.36,-,-,-,-,-,-,-,-, 0.59,-,-,-,-,-,-,-, 0.46, 0.25,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.25,-,-,-,-, 0.40, 0.48,-,-, 0.41,-,-,-,-,-,-,-,-,-,-,-,-, 0.43,-,-,-,-,-,-,-, 2.23,-, 0.37,-,-,-, 0.47,-,-, 0.36,-,-,-,-,-,-,-, 0.32,-,-,-,-,-, 0.30,-,-,-,-,-,-,-,-,-, 0.68,-,-, 0.21,-,-, 0.36,-,-,-, 0.43, 0.20,-, 0.31,-,-,-,-,-, 0.41,-,-,-,-, 0.33, 0.34,-,-,-,-,-, 0.84,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 1.37,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-,-, 0.39, 1.43,-,-,-, 0.41,-,-,-,-,-,-, 0.31, 0.36,-,-,-,-,-,-,-,-, 0.34, 0.33, 0.44, 0.18, 0.34,-, 0.45,-,-,-,-,-,-,-, 0.39,-,-,-, 0.34,-, 0.32,-, 0.28,-,-, 0.38,-,-,-, 0.32,-, 0.33,-,-,-,-, 0.36,-,-, 0.47, 0.38,-,-, 0.47, 0.50,-,-,-,-,-,-, 0.24,-,-,-,-,-,-, 0.30,-,-,-,-,-, 0.40,-, 0.21,-,-,-,-,-, 0.40, 0.30, 4.14, 0.28,-, 0.37,-,-, 1.19,-, 0.07, 0.21, 0.43,-, 0.53,-,-,-, 9.77, 0.50,-,-,-, 0.31,-, lr of zeroth group 1.2458333333333336e-05 data time  2.59 step time  0.58 forward time  0.19 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 405.94s | mean loss  0.52 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.67,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.57, 0.41,-,-,-,-,-,-, 0.57,-,-,-,-, 0.37,-,-,-, 0.37,-,-,-, 0.41, 0.37,-,-,-, 0.32,-,-,-, 0.51,-,-, 0.41,-,-,-,-, 0.51,-,-, 1.17,-,-,-, 1.30,-, 0.55,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.42,-,-,-,-, 0.50,-,-,-,-,-,-,-, 0.26,-,-,-,-,-,-,-, 1.18,-,-,-,-,-, 0.71,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.40,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.29,-,-,-,-,-, 0.38,-,-,-,-,-,-,-,-,-,-,-, 0.33,-,-,-,-,-,-,-,-,-, 0.31, 0.41,-,-,-, 0.28,-,-, 0.56,-,-,-,-,-,-,-,-,-, 0.95,-, 0.27,-,-,-, 0.28,-,-,-,-,-,-, 0.50,-,-,-,-,-,-, 1.07,-, 1.15,-, 0.37,-, 0.38,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-,-,-,-,-,-,-,-, 0.98,-,-,-,-,-,-,-, 0.42,-,-, 0.31,-,-,-, 0.56,-,-,-,-,-, 0.24,-,-,-,-,-, 0.38,-,-,-,-, 0.42,-,-,-,-,-, 0.37,-,-,-,-, 0.24,-, 0.30,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-, 2.01,-,-,-,-,-,-,-,-, 0.45,-,-,-,-,-,-,-,-, 0.21,-,-,-,-,-,-,-,-, 0.35,-,-,-,-, 0.32,-,-,-,-, 1.46,-, 0.29,-,-,-,-,-,-, 0.31,-,-,-,-, 1.87,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.38,-,-,-,-, 0.24,-, 0.35,-,-,-,-,-, 0.38,-,-,-,-,-,-,-, 0.23,-, 0.21,-, 0.31,-,-,-, 0.33,-, 0.31, 0.28,-, 0.33,-, 0.32,-,-,-, 0.50,-,-,-,-, 0.67,-, 0.33,-,-,-,-,-,-,-, 0.24, 0.22, 0.26,-,-,-, 0.23,-,-,-,-, 0.49,-, 0.39, 0.39,-,-,-, 0.24,-,-, 0.21,-, 0.41,-,-, 0.31,-, 0.36, 0.49,-, 0.30, 0.26, 0.24,-,-, 0.23,-, 0.31,-, lr of zeroth group 1.6625000000000004e-05 data time  3.09 step time  0.99 forward time  0.34 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 399.53s | mean loss  0.40 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.37,-,-,-,-,-,-,-,-,-, 0.17,-, 0.56,-,-, 0.26,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.30, 0.31,-,-,-, 0.58,-,-,-,-, 0.38,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.26, 0.34,-,-,-,-, 0.47,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.79,-,-,-,-,-,-,-,-,-, 0.80,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.23,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.44,-,-,-,-,-,-,-,-,-,-,-,-, 0.27,-,-,-,-,-,-,-,-,-,-,-, 0.40,-,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-, 0.78,-,-,-,-,-, 0.27,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.61,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-, 0.21,-,-,-,-,-,-,-,-, 0.20,-,-, 0.41,-,-,-,-,-,-, 0.81,-,-, 0.20,-, 0.14,-,-,-,-,-,-,-,-,-,-,-,-, 0.95,-,-,-,-, 1.07,-,-, 1.16,-,-,-,-,-,-,-,-,-,-,-, 0.22,-, 0.22,-,-,-,-,-, 0.25,-,-,-,-,-,-, 0.25,-,-, 0.27,-,-,-,-,-,-,-, 0.09,-,-,-,-, 0.13,-,-,-,-,-,-,-, 0.25,-,-, 0.19,-,-, 1.31,-,-,-,-,-,-, 0.17,-,-, 0.19,-, 0.41,-,-,-,-,-,-,-, 0.22, 0.14,-,-,-,-,-,-,-,-, 0.35, 1.19,-, 1.54,-,-,-, 0.32,-, 2.62,-,-, 0.25,-,-, 0.66,-, 0.06,-, 0.21,-,-,-,-, 0.37,-,-,-,-,-,-,-,-,-,-,-,-, 0.52, 0.50,-,-, 0.22,-, 0.25,-,-, 0.42,-,-, 0.14, 0.31,-,-,-, 0.27,-, 2.51,-,-,-,-,-,-, 0.24,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.16,-,-, 0.39,-,-,-, 0.17,-, 0.42, 0.21,-,-,-,-,-,-,-,-, 0.05, 0.19,-,-, 0.16,-,-, 0.30, 0.09,-, 0.27, 0.32,-, 0.15, 0.34, 0.24,-,-, 0.23, 0.22,-, 0.10,-,-, 0.30, 0.14, 0.13, 0.34,-,-,-, lr of zeroth group 2.0791666666666666e-05 data time  4.32 step time  1.00 forward time  0.34 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 451.33s | mean loss  0.25 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-,-,-,-, 0.17,-,-,-, 0.04,-,-,-,-,-,-,-,-,-, 0.52,-,-, 0.43,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-, 0.41, 0.51,-,-,-, 0.39,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.06,-,-,-,-,-,-,-, 0.10,-,-, 0.07,-,-,-,-, 0.24,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.75,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-, 0.05,-, 0.47,-,-, 0.06,-,-,-,-,-, 0.04,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-,-,-,-, 0.30,-,-,-, 0.26,-,-,-,-,-,-,-,-,-, 0.06,-,-, 0.49,-,-,-,-,-,-,-,-, 0.03,-,-,-,-, 0.19, 0.06,-,-,-,-, 0.08, 0.12,-,-,-,-, 0.13,-,-,-,-, 0.05,-,-,-, 0.04,-,-,-,-, 0.10,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.75, 0.56,-,-,-,-, 0.14,-,-,-,-,-,-, 0.04,-,-,-,-,-,-,-, 0.09,-,-,-,-,-, 0.06,-, 0.12,-,-,-,-,-, 0.58,-,-,-,-,-,-,-,-, 0.09,-,-, 0.08,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-, 0.59,-,-,-,-, 0.06,-,-, 0.11,-,-,-,-, 0.17,-, 0.07,-,-,-,-, 0.09,-, 0.07,-,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-, 0.03,-,-, 0.10, 0.06, 0.04,-, 0.10,-,-,-,-, 0.61,-,-,-,-,-, 0.08,-, 0.07,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-, 0.03,-,-, 0.10,-,-, 0.06,-,-,-,-, 0.04,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-,-,-,-,-,-, 3.40, 0.07,-,-, 0.15,-, 0.06,-,-,-, 0.12,-,-,-,-,-,-, 0.04,-,-, 0.04, 0.09,-, 0.06,-, 0.08,-, 0.09, 0.07, 0.05, 0.07,-,-,-,-,-, 0.10,-,-,-,-, 0.01, 0.31,-, lr of zeroth group 2.4958333333333338e-05 data time  2.71 step time  1.01 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 393.73s | mean loss  0.23 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.38,-,-,-,-,-,-,-, 0.51,-,-, 0.22,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-, 0.21,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05, 0.27,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-, 0.29,-,-,-,-,-,-, 1.17,-, 0.75,-,-,-,-, 0.44,-,-,-,-,-, 0.84,-, 0.04,-,-,-,-,-, 0.07,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-, 0.06,-,-,-,-, 0.21,-, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05, 0.08,-,-, 0.03,-,-,-,-,-,-, 0.32,-, 0.03,-,-,-,-,-,-, 0.05,-,-,-,-, 0.07,-,-,-,-,-, 0.13,-,-,-, 0.03,-,-, 0.03,-,-,-,-,-,-,-, 0.04,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-, 0.26, 0.04,-, 0.08,-, 0.66,-, 0.03,-,-,-,-,-,-, 0.02,-, 0.03,-,-,-,-,-,-,-, 0.03,-, 0.03, 1.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-, 0.10,-,-,-,-,-,-, 0.51,-,-,-,-,-,-,-, 0.04, 0.03,-, 0.06,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-, 0.06, 0.88,-,-,-,-, 5.09, 1.96,-,-,-,-,-, 0.02,-,-, 0.06,-,-,-, 0.01,-,-, 0.02,-,-, 0.05,-,-, 0.03, 0.05, 0.04, 0.04, 0.04,-,-, 0.03,-,-, 0.05,-, 0.02,-,-,-,-, 0.04, 0.02,-,-,-,-,-, 0.02, 0.04,-, 0.03, 0.02, 0.05, 0.04, 0.07, 0.06,-,-,-, 0.02, 0.02,-,-,-,-,-, 0.03,-,-,-, 0.02,-, 0.08, 0.05,-, lr of zeroth group 2.9125000000000003e-05 data time  2.98 step time  0.97 forward time  0.36 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 387.88s | mean loss  0.18 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.28,-,-,-,-,-,-, 0.51,-, 0.80,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.18,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.24,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-, 0.32,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.95,-,-,-,-,-,-,-,-,-, 0.67, 0.03, 0.44,-,-,-,-,-,-,-,-,-,-,-, 0.51,-,-, 0.02,-,-, 0.15,-,-,-,-,-,-,-,-,-, 0.44,-,-,-,-,-,-,-,-,-, 0.23,-,-,-, 0.21,-, 0.22,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.46,-,-, 0.33, 0.01,-,-,-, 0.03,-,-, 0.44,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.25,-,-, 0.01,-,-,-,-, 0.02,-, 0.02, 0.02, 0.48,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-, 0.30,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-, 0.18,-,-,-,-,-,-,-,-, 0.98,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.01,-, 0.03, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-, 0.05,-,-,-, 0.01, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-, 0.02,-, 0.05,-, 0.02,-,-,-,-, 0.03,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 2.30,-, 0.03, 0.04,-, 0.02,-,-,-,-, 0.04,-,-,-, 0.02, 0.05, 0.04,-,-,-, 0.02,-,-,-,-,-,-,-, 0.01,-, 2.17,-,-,-,-,-,-,-,-, 0.02,-,-, 0.02,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.03,-,-, 0.02,-,-,-, 0.01,-, 0.02, 0.03,-, 0.02, 0.04,-, 0.02,-,-,-,-,-, 0.01,-, 0.01,-,-, 0.01, 0.04, 0.02,-, 0.01, 0.01, 0.01,-,-, 0.00,-, lr of zeroth group 3.329166666666667e-05 data time  2.95 step time  0.84 forward time  0.30 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 402.71s | mean loss  0.14 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-, 0.27,-,-,-,-,-,-,-,-,-,-,-,-, 0.41,-,-,-, 0.14,-,-,-,-,-,-, 0.42,-,-,-,-,-,-,-, 0.32,-,-,-,-, 0.02, 0.12,-,-,-,-,-,-,-, 0.27,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.12,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.32,-,-,-,-, 0.02,-,-, 0.03,-,-,-,-,-,-,-, 0.56,-,-, 0.36,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19,-, 0.02,-,-, 0.21,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.15,-,-,-,-,-,-, 0.46, 0.02,-,-,-,-,-, 0.57,-,-,-, 1.09,-,-, 0.02,-,-, 0.02,-,-,-,-,-,-, 0.26, 0.03, 0.03,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.87, 0.34,-,-, 0.50,-,-,-,-, 0.36,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-, 0.02,-,-,-,-,-,-, 0.03,-, 0.03,-,-,-,-,-,-,-,-,-,-,-, 2.93,-,-, 0.96,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-, 0.45,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.40,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.03, 0.02, 0.02,-, 0.32,-,-, 0.01,-,-,-,-, 1.12,-,-,-,-,-, 0.02, 0.02,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01, 0.01,-, 0.02,-,-,-,-, 0.02,-,-,-, 0.03, 0.03,-,-,-,-,-,-,-,-,-,-,-, 0.03, 0.03,-, 1.55,-,-, 0.02,-, 0.01,-, 0.02,-, 0.02,-, 0.01,-, 0.02,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-, 0.03, 0.02, 0.02,-, 0.02,-, 0.04,-, 0.03,-, 0.01, 0.02, 0.02, 0.01, 0.01, 0.02,-, 0.02,-,-,-,-,-, 0.03, 0.02,-,-, lr of zeroth group 3.745833333333334e-05 data time  3.14 step time  0.94 forward time  0.32 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   8 | time: 401.33s | mean loss  0.14 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-,-, 0.37,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-, 0.02,-,-,-,-, 0.02,-,-,-,-,-,-,-, 0.01,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-, 0.01,-,-,-,-, 0.21,-,-,-,-,-,-, 0.02,-, 0.02,-,-,-,-,-, 0.02,-,-,-,-, 0.01,-,-,-, 0.02,-,-,-,-,-,-,-,-,-, 0.31,-,-,-, 0.01,-,-, 0.02, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.28, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.02,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.02,-,-,-, 0.61,-,-,-,-, 0.33,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-, 0.67, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-, 0.01,-, 0.03,-,-, 0.02,-,-,-,-,-,-, 0.28,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01, 0.02, 0.04,-,-,-, 0.02,-, 0.04,-,-,-,-,-,-, 0.02,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.03,-,-,-,-,-, 0.02,-,-, 0.02,-,-, 0.04,-,-,-,-,-, 0.02,-,-,-,-,-, 0.02,-,-,-,-,-, 0.03,-,-,-,-, 0.02, 0.02,-,-, 1.83,-, 0.03,-, 0.01,-,-,-,-,-,-,-,-, 0.03,-, 0.02, 0.01,-,-,-, 0.03,-, 0.01, 0.02,-, 0.02,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.01, 0.04,-,-, 0.03, 0.01, 0.01, 0.03,-, 0.01,-, 0.02,-, 0.01, 0.01,-, 0.02,-,-, 0.00,-,-, lr of zeroth group 4.1625e-05 data time  2.88 step time  0.75 forward time  0.25 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   9 | time: 384.69s | mean loss  0.16 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.13,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-, 0.02,-, 0.29,-,-,-,-,-,-,-,-,-, 0.11,-, 0.01, 0.13,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.31,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-,-,-,-,-, 0.34,-,-,-,-,-,-,-, 0.24,-,-,-,-,-,-, 0.17,-, 0.01, 0.26,-, 0.75,-,-, 0.57,-,-,-,-,-,-,-,-,-,-, 0.29,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.14,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-, 0.02, 0.02,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.30, 0.01,-,-,-,-,-, 0.02,-,-,-, 0.02, 0.01,-,-,-, 0.02, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.59,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.05,-,-,-,-, 0.01,-,-,-,-, 0.01, 0.02,-,-,-,-,-,-, 0.01, 0.01,-,-,-, 0.04,-,-,-,-,-, 0.01, 0.02,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-, 0.84,-,-,-,-,-,-,-,-, 0.69,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.02,-,-,-,-,-,-, 0.02, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-, 0.31,-,-, 0.12, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-, 1.36,-, 0.02, 0.01,-,-, 0.03,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-, 0.14, 0.01,-,-,-,-,-, 0.03,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-, 0.01, 0.03,-,-,-, 0.00,-, 0.02,-,-,-,-,-, 0.01,-, 0.13, 0.04,-,-,-,-, 7.85,-, 0.00, 0.02,-, lr of zeroth group 4.579166666666667e-05 data time  2.94 step time  0.65 forward time  0.22 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  10 | time: 388.10s | mean loss  0.13 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.02,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.16,-, 0.12,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.14,-,-,-,-, 1.15,-,-, 0.35,-,-,-,-,-,-,-, 0.09,-,-,-,-, 0.18,-,-,-, 0.14,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-,-, 0.01,-,-, 0.23, 0.01,-,-,-, 0.02,-, 0.02,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.24,-, 0.34,-,-, 0.52, 0.13,-,-,-,-, 0.42,-, 0.43,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.36,-,-,-,-,-,-,-,-, 0.21,-,-,-,-,-,-,-, 0.04, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.32, 0.02, 0.01, 0.02,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.02,-,-,-,-,-,-, 0.02, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.25, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 1.72, 0.01, 0.01,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-, 0.01,-,-,-,-, 0.94,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 1.14,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.02,-,-, 0.02, 0.02, 0.02, 0.01, 0.67,-,-, 0.02, 0.05,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.02,-,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01, 0.01,-, 0.02,-,-,-, 0.01,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.02, 0.01,-,-,-,-,-, 0.02,-, 1.17,-,-,-,-,-,-,-, 0.01, 0.01,-, 0.01, 0.03, 0.02,-, lr of zeroth group 4.995833333333334e-05 data time  3.00 step time  0.66 forward time  0.22 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  11 | time: 391.63s | mean loss  0.14 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.64, 0.11,-,-,-,-,-,-,-,-, 0.03,-, 0.25,-,-,-,-, 0.01,-,-,-,-,-, 0.14,-,-,-,-,-,-,-,-,-,-,-, 0.65,-,-,-,-,-,-,-, 0.02, 0.07,-,-,-,-, 0.22,-,-, 0.23,-,-,-,-,-, 0.01, 0.32,-, 0.03,-,-, 0.02,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.18,-,-,-,-, 0.29,-,-, 0.26,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.18,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.53,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.45,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-, 0.01, 0.02,-,-,-,-, 0.02,-,-,-,-,-,-,-,-, 0.23,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.50,-, 1.09, 0.43,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-, 1.32,-,-,-, 1.46,-,-, 0.02, 0.02,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-, 0.01, 0.02,-, 0.01,-,-,-,-,-, 0.01,-, 0.15,-,-,-,-, 0.01,-,-, 1.01, 0.02, 0.01,-, 0.01,-,-,-,-,-, 0.01, 0.01,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.02,-, 1.68,-, 0.01, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.02,-, 0.04,-, 1.48, 0.02,-,-,-,-, 0.02,-,-,-, 0.01,-, 0.02, 0.01, 0.02,-, 0.01,-,-, 0.02, 1.54,-, 0.02, 0.01, 0.02,-,-,-, 0.01, 0.01,-, 0.01, 0.07, 0.01,-, 0.01,-, lr of zeroth group 4.99163105912123e-05 data time  2.88 step time  0.61 forward time  0.21 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  12 | time: 388.64s | mean loss  0.12 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-, 0.39,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-, 0.44,-,-,-,-, 0.14,-,-,-,-,-, 0.35,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-, 0.28,-,-,-, 0.47, 0.01,-,-, 0.01,-, 0.02, 0.24,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.13,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.50,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.02,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.25,-, 0.26,-,-,-, 0.19, 0.01, 0.01, 0.02,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.02,-, 0.01, 0.53,-,-,-, 0.69,-,-, 0.01, 0.01,-,-,-, 0.01,-, 0.01,-,-,-,-, 0.03,-,-,-, 0.01,-, 0.01,-, 0.02, 0.02,-, 0.39,-,-, 0.01,-,-,-, 0.02,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.02, 0.01,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.02,-,-,-, 0.01,-,-,-,-, 0.66,-,-,-, 0.01, 0.02,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-,-,-, 0.03, 0.01,-, 0.04,-,-, 0.01, 0.01,-, 0.01,-,-,-, 0.01,-, 0.02,-, 0.01, 0.02, 0.07, 0.02,-, 0.02, 0.00, 3.73, 0.01,-,-, lr of zeroth group 4.9662426059912184e-05 data time  3.29 step time  0.65 forward time  0.22 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  13 | time: 384.64s | mean loss  0.10 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.24,-,-,-,-,-,-,-,-, 0.18, 0.02, 0.08,-,-,-,-,-, 0.14,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.24, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.09,-, 0.06,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-, 0.02,-, 0.01,-,-,-,-, 0.02,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.57,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.26,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.23,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.03, 0.01, 0.02,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.02,-,-, 0.02,-, 0.37,-,-,-,-,-,-,-,-,-,-, 0.33,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.51,-,-,-,-,-,-,-,-,-,-,-, 0.48,-, 0.01,-,-, 0.01,-,-,-,-,-, 0.02, 0.40,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-, 0.02,-, 0.01, 0.02, 0.02,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.02,-, 0.01, 0.30,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-, 0.01,-,-, 1.26,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.32,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-, 0.02,-, 0.03,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-, 0.01, 0.02,-,-, 0.01,-,-, 0.02,-, 0.01,-, 0.03,-,-,-, 0.01,-,-, 0.01, 0.01,-,-,-, 0.02,-, 0.02,-, 1.15, 0.01,-,-,-, 0.01,-,-,-, 0.03,-,-,-,-, 0.01,-, 0.03,-, lr of zeroth group 4.9240072151251834e-05 data time  3.16 step time  0.80 forward time  0.27 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  14 | time: 455.64s | mean loss  0.11 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-, 0.10, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.25,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.14,-,-,-,-,-,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.96, 0.07, 0.43,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.22, 0.02,-, 0.01,-,-, 0.02,-,-,-, 0.01, 0.02,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-, 0.01, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.25,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.43,-,-,-,-,-,-, 0.33,-, 0.01,-, 0.01,-,-, 0.02,-,-, 0.02,-,-,-, 0.01, 0.01, 0.01,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.02, 0.01,-,-,-,-,-,-,-,-,-, 0.33,-,-,-, 0.01,-, 0.75, 0.02,-,-,-, 0.58,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-, 0.01,-,-,-, 0.01,-,-, 0.29, 0.01,-, 0.70,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.28,-, 0.00,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-, 0.60,-, 0.02, 0.01,-, 0.53,-,-, 0.01, 0.18,-,-,-,-,-,-,-, 0.01,-, 0.02, 0.01, 0.01,-,-,-,-,-,-,-, 0.02,-,-,-, 0.02, 0.03,-,-, 0.01,-,-,-, 0.01,-, 0.02,-,-, 0.01,-,-, 0.01, 0.01, 0.01,-,-, 0.02,-, 0.01,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-, 0.03, 0.02,-,-,-,-, 0.01,-,-, 0.02,-, lr of zeroth group 4.8652133970688636e-05 data time  2.79 step time  0.98 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  15 | time: 427.70s | mean loss  0.12 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.35,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-,-,-, 0.23,-,-,-,-,-,-,-,-, 0.15,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.22,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.38,-,-,-,-,-, 0.03,-,-,-,-,-,-, 0.12,-,-,-, 0.24,-, 0.15, 0.10,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.22,-,-,-, 0.02,-, 0.18,-,-,-,-,-, 0.03, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.02,-,-,-, 0.01, 0.01,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 1.27,-,-,-, 0.08,-,-,-,-,-,-,-,-,-, 0.58,-, 0.02,-,-,-,-,-,-,-, 0.02, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-, 0.02, 0.01,-,-,-,-,-,-,-,-,-, 0.41,-, 0.03,-,-,-,-,-,-, 0.03,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-, 0.55,-,-, 0.03,-,-,-,-, 0.01,-,-, 0.03, 0.02,-,-,-,-, 0.01, 0.43,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.02,-, 0.01,-, 0.00,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.02,-,-,-, 2.04, 0.02,-, 0.02,-,-,-, 0.01,-, 0.01,-, 0.01, 0.02,-,-, 0.02, 0.01,-, 0.01,-,-,-, 0.01,-,-, 0.01, 0.03, 0.00, 0.87,-, lr of zeroth group 4.7902627732157294e-05 data time  3.20 step time  0.67 forward time  0.23 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  16 | time: 395.01s | mean loss  0.11 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.31,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.18,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-, 0.03,-,-,-,-,-,-,-,-, 0.18,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.30,-,-,-,-,-, 0.02, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-, 0.23,-,-,-,-,-,-,-, 0.22,-,-,-,-,-,-,-, 0.01, 0.01,-,-, 0.50,-,-,-,-,-,-, 0.01,-,-,-,-, 0.13,-, 0.29,-, 0.75,-,-, 0.12,-, 0.21, 0.26,-,-,-,-,-,-,-, 0.16,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.37,-,-, 0.24,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.65,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-, 0.46,-,-,-, 1.20,-,-,-,-,-,-, 0.01,-, 0.02,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-, 0.01,-, 0.31,-, 0.22,-,-,-,-,-,-, 0.01, 0.25,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.36,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.16,-,-,-, 0.09, 0.01,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-, 0.47,-,-, 0.01, 0.01, 0.01,-, 0.01, 0.01, 0.01,-,-,-, 0.28, 0.01,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-, 0.01,-, 0.00, 0.01,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-, 0.01,-, 0.01, 0.02,-, 0.01,-, 0.01, 0.01,-,-,-, 0.01, 0.02, 0.00,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.02, 0.02,-, 0.01,-, 0.02, 0.01, 0.01,-,-,-,-, 0.01, 0.00, 0.00,-, lr of zeroth group 4.699667332325631e-05 data time  2.70 step time  0.59 forward time  0.20 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  17 | time: 388.38s | mean loss  0.11 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.02,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.26,-, 0.01,-,-,-,-,-,-, 0.01, 0.16,-,-,-,-, 0.11,-,-, 0.01,-,-,-, 0.60,-,-,-,-,-,-,-,-,-, 0.12, 0.26,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-, 0.12, 0.25,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01, 0.01, 0.07,-,-,-,-, 0.01,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.35, 0.27,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.22,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.02,-,-,-,-,-, 0.02,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.02, 0.01,-, 0.01,-,-,-,-, 0.01,-, 0.13,-,-,-, 0.22,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.35,-,-,-, 0.01,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-, 0.02,-,-,-,-, 0.01,-,-,-, 0.38, 0.01, 0.01,-, 0.01,-,-,-, 0.02,-, 0.91,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-, 0.01, 0.22,-,-,-, 0.69, 0.23,-, 0.01,-, 0.67,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01, 0.01, 0.03,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-, 0.95,-, 0.01,-,-,-, 0.01,-,-,-,-,-, 0.02, 0.00, 0.01, 0.01,-, 0.00,-,-,-, 0.01,-,-, 0.01,-,-, 0.01,-,-,-, 0.00, 0.01,-,-, 0.00,-,-, lr of zeroth group 4.594045933122417e-05 data time  3.95 step time  0.60 forward time  0.20 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  18 | time: 442.08s | mean loss  0.09 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-, 0.01, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.41,-,-,-,-,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.18, 0.01, 0.15,-,-,-,-,-,-, 0.02, 0.02,-,-,-,-,-,-,-,-, 0.12,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.43,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.12,-,-,-, 0.02,-,-,-,-,-, 0.04, 0.29, 0.01, 0.07,-,-,-,-,-,-,-,-,-,-, 0.23,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.30,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-, 0.11,-,-,-,-,-,-,-, 0.01,-,-,-, 0.19,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.02,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-, 0.25, 0.02,-,-,-,-,-, 0.01,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-, 0.80,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.41,-,-,-, 0.01, 0.01,-,-,-, 1.03, 0.01,-,-,-,-,-, 0.03,-, 0.01,-, 0.46,-, 0.01, 0.01,-,-,-,-,-,-,-,-, 0.23,-,-,-,-,-,-, 0.95,-,-,-,-,-,-,-, 0.63, 1.89,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01, 0.15, 0.02,-, 0.00,-,-,-,-, 0.01, 0.01,-,-,-, 0.01,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.02, 0.01,-, 0.03,-,-,-, 0.01,-, 0.01, 0.01, 0.01, 0.01,-, 0.02,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.02,-, 0.01,-,-, 0.00,-,-, lr of zeroth group 4.474120076861335e-05 data time  2.62 step time  0.94 forward time  0.32 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  19 | time: 384.42s | mean loss  0.10 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01, 0.01,-,-,-,-, 0.26,-,-,-, 0.01,-,-, 0.03,-,-, 0.02,-,-,-,-,-,-,-,-,-, 0.23,-,-,-,-, 0.01,-,-,-, 0.16,-,-,-,-,-, 0.27,-,-,-, 0.01, 0.01, 0.19,-,-, 0.01,-,-, 0.16,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-, 0.12,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-, 0.20,-,-, 0.13,-,-,-, 0.02, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-, 0.17, 0.01,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.14,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-, 0.17,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.37,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-, 0.01, 0.02, 0.12,-, 0.66,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.21,-,-,-,-, 0.28,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01, 0.04, 0.00,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.18,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-, 0.01,-, 0.03,-,-, 0.01, 0.01, 0.01,-, 0.01, 0.01,-, 0.01, 0.01, 0.01, 0.02,-,-, 0.01, 0.00, 0.01,-, 0.00, 0.01, 0.00,-, lr of zeroth group 4.3407089787438646e-05 data time  2.78 step time  0.82 forward time  0.28 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  20 | time: 390.07s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.04, 0.08,-,-,-,-,-,-,-,-, 0.06,-,-,-, 0.23,-,-,-,-,-,-,-,-,-, 0.61,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.09,-, 0.06,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.59,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-, 0.04,-,-,-,-,-,-, 0.17,-,-,-, 0.23, 0.25,-,-,-,-,-,-,-, 0.10, 0.18,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.34,-,-,-,-, 0.01,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.23,-, 0.01,-,-,-,-,-,-,-,-, 0.01, 0.31,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-, 0.01,-,-,-,-, 0.82,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.06,-,-,-, 0.10,-,-, 0.02,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-, 0.01, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-, 0.01,-,-, 0.01,-,-, 0.01,-,-, 0.01,-,-, 0.02,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.19, 0.01, 0.02,-,-,-, 0.01,-, 0.01,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-,-, 0.25, 0.01,-, 0.00,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-, 0.01,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00, 0.01,-, 0.00,-,-,-, 0.00, 0.04,-, 0.01, 0.00, 0.02,-, lr of zeroth group 4.1947239718472256e-05 data time  2.70 step time  1.02 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  21 | time: 391.25s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13, 0.28,-,-,-, 0.02,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.14,-,-,-,-,-,-,-, 0.00,-,-,-, 0.09,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-, 0.01,-, 0.08,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.10,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-, 0.21,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.76, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.57, 0.01,-,-,-,-,-,-, 0.01,-, 0.02,-, 0.01,-, 0.12,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.18,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.02,-,-,-,-,-, 0.18,-,-,-, 0.01,-,-, 0.15,-,-,-,-,-,-,-,-,-,-,-, 0.26, 0.26,-,-, 0.00,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.02,-,-,-, 0.01, 0.66,-,-,-,-, 0.02, 0.01, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-, 0.00, 0.01,-,-, 0.01,-,-,-,-,-,-, 0.01, 0.01,-, 0.01, 0.01,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-, 0.05, 0.01,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.00,-,-,-,-, 0.01, 0.02,-,-, 0.00, 0.01, 0.00,-, lr of zeroth group 4.037162281795368e-05 data time  3.04 step time  0.76 forward time  0.25 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  22 | time: 390.86s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.27,-, 0.01,-, 0.00,-,-,-,-,-,-, 0.01,-,-, 0.31,-,-,-, 0.12,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.49,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.02, 0.01,-,-,-,-, 0.25,-, 0.01, 0.06,-,-,-,-,-, 0.01,-,-,-, 0.20,-, 0.09,-,-,-, 0.02,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.04,-,-,-,-,-, 0.00, 0.01,-,-,-,-, 0.21,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.22,-,-,-, 0.03, 0.34,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-, 0.01,-, 0.01,-, 0.15,-,-,-,-, 0.21,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.03, 0.13, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-, 0.19,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.12,-,-,-, 0.00,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.56,-, 0.01,-, 0.01,-,-,-,-, 0.04,-,-, 0.48, 0.01, 0.01,-, 0.01,-, 0.00,-,-,-,-,-,-, 0.01,-, 0.03,-,-,-, 0.02,-, 0.02, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01, 0.01,-,-, 0.01,-, 0.01, 0.01,-,-,-, 0.00, 0.01,-, 0.01,-, lr of zeroth group 3.869100214696801e-05 data time  3.51 step time  0.69 forward time  0.23 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  23 | time: 390.50s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.48,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.10,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.08,-,-,-,-, 0.10,-,-,-, 0.02,-, 0.46,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.10, 0.22,-,-,-,-, 0.01, 0.00, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.09,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.01,-,-, 0.06, 0.10,-,-,-, 0.69,-,-, 0.23,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.23,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-, 0.14,-,-,-,-,-,-,-,-, 0.01,-, 0.09,-,-, 0.01,-,-,-, 0.00,-, 0.01,-,-,-,-, 0.01, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-, 0.01, 0.00, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.14, 0.01,-,-,-,-,-,-,-, 0.49,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.32,-,-,-, 0.41,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01, 0.41,-,-,-,-,-,-,-, 0.01, 0.01,-,-, 0.01,-,-,-,-,-, 0.01,-, 1.05,-, 0.01,-,-, 0.01,-,-, 0.01,-, 0.01,-,-,-, 0.01, 0.00,-,-,-,-, 0.63,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.02, 0.01,-,-, 0.00,-,-, 0.01,-,-, 0.01,-,-,-,-, 0.03,-,-, 0.01, 0.01, 0.01, 0.01, 0.00,-, 0.18,-, 0.11, 0.00, 0.01,-,-, lr of zeroth group 3.6916858048824996e-05 data time  3.34 step time  1.02 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  24 | time: 396.02s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-,-,-, 0.05,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-, 0.06,-,-,-,-,-,-,-,-, 0.04,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.09,-,-,-,-,-, 0.01,-,-,-, 0.11,-,-,-,-,-, 0.01,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-, 0.01,-,-,-,-, 0.12, 0.01,-,-,-, 0.01,-, 0.01,-,-,-, 0.17,-,-,-,-,-,-,-,-, 0.01,-,-, 0.15,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.19,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19,-, 0.01,-,-, 0.01,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.20,-,-,-, 0.01, 0.01,-, 0.00,-,-, 0.00, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-, 0.02,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.01, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.02,-,-,-,-,-, 0.01, 0.01,-, 0.00,-,-,-,-, 0.01,-, 0.01,-, 0.01, 0.00,-, 0.01, 0.01,-,-, 0.01, 0.01,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.10,-,-, 0.01, 0.01,-, 0.01, 0.04,-, 0.01,-, 0.01, 0.00, 0.01, 0.01,-,-, 0.02,-,-,-,-,-,-, 0.00,-, lr of zeroth group 3.506130972667342e-05 data time  3.34 step time  0.92 forward time  0.30 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  25 | time: 446.91s | mean loss  0.07 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-, 0.01, 0.00,-, 0.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-, 0.19, 0.20, 0.16,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08, 0.25,-,-,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-, 0.06,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.02,-,-,-,-,-,-, 0.01,-, 0.12,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.16,-,-,-, 0.22,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-, 0.01,-, 0.02,-,-,-,-,-, 0.01,-,-, 0.36,-, 0.01, 0.01,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.31,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.01, 0.00, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-, 0.12,-, 0.49,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-, 0.19,-,-, 0.49,-,-, 0.01,-,-,-,-,-, 0.01,-, 0.01, 0.01,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-,-, 0.01,-,-, 0.01, 0.18, 0.01,-,-,-,-, 0.01,-, 0.00,-, 0.01, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-, 0.01,-, 0.01, 0.02, 0.00,-,-, 0.00, 0.02,-, 0.01, 0.00,-,-,-,-, lr of zeroth group 3.31370324570548e-05 data time  4.40 step time  0.75 forward time  0.25 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  26 | time: 401.36s | mean loss  0.09 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.28,-, 0.00,-,-,-,-, 0.09,-,-, 0.10,-,-,-,-,-,-,-,-,-, 0.12,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.54,-,-,-, 0.23,-, 0.08,-,-,-, 0.15,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-, 0.01,-,-, 0.07, 0.01,-,-,-,-,-,-,-,-,-, 0.19,-, 0.09,-, 0.09,-,-,-, 0.20,-, 0.03,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.15,-,-,-, 0.05,-,-,-, 0.03,-,-,-,-,-,-,-,-, 0.33,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.03,-,-,-, 0.69,-,-,-,-, 0.01,-,-, 0.00,-,-,-, 0.35, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-, 0.10,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-,-, 0.03,-,-,-, 0.14, 0.01, 0.22,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-, 0.01, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01, 0.02, 0.01,-,-,-,-,-,-, 0.01,-, 0.02, 0.00,-,-,-,-,-,-, 0.01, 0.01,-,-,-, 0.01,-,-, 0.01,-,-, 0.01,-, 0.01, 0.01, 0.01, 0.01,-,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.00, 0.01, 0.00, 0.02,-, lr of zeroth group 3.115717100491215e-05 data time  2.84 step time  0.72 forward time  0.24 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  27 | time: 391.81s | mean loss  0.09 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.06,-,-,-,-,-, 0.14,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.19,-,-,-,-, 0.00, 0.10,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.18,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-, 0.02, 0.19,-,-,-,-, 0.00,-,-,-,-, 0.09,-,-,-,-, 0.00,-,-,-,-,-, 0.89,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.32,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-, 0.01,-, 0.01,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-, 0.02,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-, 0.22, 0.01, 0.04,-, 0.00,-,-, 0.01,-, 0.01, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-, 0.01,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.52,-, 0.01,-,-,-, 0.26,-,-,-,-,-, 0.00,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.01,-, 0.01, 0.61,-,-, 0.02,-, 0.00,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-, 0.00,-, 0.01,-,-, 0.01,-,-,-,-, 0.01,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-, 0.01,-, 0.01, 0.00, 0.01, 0.01,-, 0.02,-, 0.00, 0.59, 0.01, 0.01,-, lr of zeroth group 2.9135249831516675e-05 data time  3.16 step time  0.72 forward time  0.24 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  28 | time: 394.97s | mean loss  0.11 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.06,-, 0.11,-,-, 0.02,-,-, 0.00,-,-,-,-,-,-, 0.03, 0.01,-,-,-,-,-,-,-,-, 0.55,-,-,-,-,-, 0.01,-, 0.06,-,-,-,-,-,-, 0.01,-, 0.00, 0.00, 0.16,-,-,-,-,-,-,-,-,-, 0.40,-,-,-, 0.05,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-, 0.11,-,-,-,-, 0.12,-,-,-, 0.02,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.23, 0.01, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-, 0.00, 0.00,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.21, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-, 0.01,-,-, 0.00, 0.01,-, 0.01,-,-, 0.01,-,-,-,-,-, 0.00,-,-, 0.01, 0.01,-,-,-, 0.00,-, 0.00,-, 0.01, 0.00,-,-,-, 0.01, 0.01,-,-,-, 0.00, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01, 0.71,-, lr of zeroth group 2.708508070868378e-05 data time  3.72 step time  0.77 forward time  0.28 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  29 | time: 418.73s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07, 0.03,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.15,-,-,-,-, 0.11,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-, 0.01, 0.12,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.10,-,-, 0.01,-, 0.26,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-, 0.33,-,-, 0.00,-,-, 0.19, 0.00,-,-,-,-,-,-,-,-, 0.06,-,-,-,-,-, 0.51,-, 0.01,-,-,-,-,-, 0.01, 0.00,-,-, 0.01, 0.01,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-, 0.01,-, 0.01,-,-, 0.01,-,-,-,-,-, 0.00, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.17, 0.01,-,-, 0.19,-,-,-, 0.17,-,-,-,-, 0.21,-,-,-,-, 0.00,-,-,-, 0.24,-,-,-,-,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.00,-, 0.69,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-, 0.20,-,-,-,-,-,-,-,-,-,-,-,-, 0.30,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-, 0.00,-,-, 0.00, 0.03,-,-,-,-, 0.01,-,-, 0.00,-, 0.00, 0.00, 0.01,-,-,-,-, 0.01,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.01, 0.00,-,-,-,-,-, 0.00, 0.00,-, 0.01, 0.03,-, 0.00,-, lr of zeroth group 2.5020668370366547e-05 data time  4.88 step time  0.90 forward time  0.30 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  30 | time: 423.73s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-, 0.01,-,-,-, 0.29,-,-,-,-,-,-,-,-,-,-,-, 0.14,-,-,-,-,-,-,-,-,-,-, 0.28, 0.01, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.01,-,-, 0.56,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.13,-,-,-,-, 0.00,-,-, 0.20,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.29,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.21,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-, 0.64,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.27,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-,-,-, 0.01,-, 0.05, 0.01, 0.26,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01, 0.01,-, 0.01,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-, 0.13,-, 0.01,-,-, 0.00,-,-,-, 0.39,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-, 0.01,-, 0.00,-, 0.01,-, 0.01,-, 0.00,-,-,-,-,-,-,-, 0.00,-, 0.01,-, 0.01,-, 0.01,-,-, 0.00,-,-,-,-,-,-, 0.08, 0.00, 0.01, 0.00,-,-,-, 0.00, 0.02, 0.01,-,-, 0.01,-, 0.01,-,-,-,-, 0.00,-, lr of zeroth group 2.2956114846122265e-05 data time  2.70 step time  1.01 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  31 | time: 401.96s | mean loss  0.07 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.25,-,-,-,-,-,-, 0.16,-,-,-,-,-,-,-,-, 0.01,-,-, 0.07,-,-,-,-,-,-, 0.22,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.32,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.02,-,-,-,-, 0.00,-, 0.01, 0.04,-, 0.16,-,-,-,-,-,-, 0.01,-, 0.27,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.05,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-, 0.24,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.00, 0.22,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.12, 0.02,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01, 0.01,-,-, 0.06,-,-,-, 0.06,-,-,-,-,-, 0.01, 0.34,-,-,-,-,-,-,-,-,-,-,-,-, 0.30, 0.17,-,-, 0.01,-, 0.14,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-, 0.19,-,-, 0.01, 0.01,-,-,-, 0.01,-,-,-, 0.00, 0.01,-,-,-,-, 0.00,-,-,-, 0.00,-,-,-,-,-,-, 0.02, 0.00,-,-,-,-, 0.09, 0.00, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-, 0.00,-, 0.00,-, 0.01,-, 0.28,-, 0.01,-,-, 0.00,-,-, 0.00, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-, 0.00, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-, 0.67,-, 0.00,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.01, 0.01,-, 0.00, 0.01,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-, 0.01, 0.01,-, 0.00, 0.00, 0.00,-, lr of zeroth group 2.0905523129951237e-05 data time  3.48 step time  0.71 forward time  0.24 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  32 | time: 391.66s | mean loss  0.07 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.24,-, 0.04,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-, 0.00,-,-, 0.18,-,-, 0.11,-,-,-,-,-, 0.21,-,-,-, 0.22,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.25,-,-, 0.00,-,-,-, 0.10,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-, 0.20,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.04,-,-,-,-,-,-,-,-, 0.40,-,-, 0.01, 0.00,-, 0.01,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.28,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-, 0.07, 0.04,-,-,-,-,-,-, 0.27,-,-,-,-,-, 0.10, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.01,-,-,-,-, 0.01,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.01,-,-,-, 0.00,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-, 0.01,-,-,-, 0.01,-,-, 0.38,-,-,-,-,-, 0.01,-,-,-, 0.13,-,-,-,-, 0.01, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-, 0.00,-,-, 0.29, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01, 0.00, 0.00,-,-,-,-, 0.01, 0.01, 0.01, 0.00, 0.01,-, 0.00,-,-,-, 0.01,-, 0.01, 0.00,-, lr of zeroth group 1.8882900842547574e-05 data time  3.46 step time  0.71 forward time  0.24 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  33 | time: 387.28s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.25,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.18,-,-,-,-,-,-, 0.06,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.14,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.22,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.25,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.51,-,-,-,-,-, 0.25,-,-,-, 0.00, 0.26,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.19, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-,-,-, 0.01,-,-,-,-,-, 0.00,-, 0.62, 0.02, 0.01,-, 0.02, 0.02,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-,-, 0.01,-, 0.00,-,-,-,-,-,-, 0.00,-,-, 0.39,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.00,-, 0.00,-,-,-,-, 0.00, 0.17,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01, 0.00, 0.01, 0.69,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.00, 0.01,-, 0.01,-,-,-,-, 0.00,-, 0.00,-,-, 0.01, 0.01, 0.00, 0.01, 0.01,-,-,-, 0.02,-,-,-,-, 0.00, 0.00, 0.01, 0.00,-, lr of zeroth group 1.6902064545046257e-05 data time  3.45 step time  0.79 forward time  0.26 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  34 | time: 474.18s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-, 0.04,-,-, 0.19,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.52,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02, 0.00,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.37,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-, 0.01,-,-,-,-, 0.00,-,-,-, 0.17,-,-, 0.01,-,-, 0.15,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.50,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-, 0.25, 0.10,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.41,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.02,-,-,-,-,-,-, 0.00,-,-,-, 0.02,-,-,-,-, 0.01, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.70,-,-,-,-,-,-,-,-,-,-, 0.01, 0.08,-,-,-,-, 0.00,-, 0.36, 0.13, 0.00,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-, 0.00, 0.00,-,-,-,-,-,-,-,-,-, 0.09,-,-,-,-, 0.17,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-, 0.01,-,-,-, 0.00, 0.01, 0.00, 0.00,-,-, 0.00,-,-, 0.00, 0.00,-,-,-, 0.01,-,-, 0.01,-,-, 0.00, 0.00,-, 0.00,-, 0.01,-,-, 0.00,-,-, 1.14, 1.60,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00, 0.00,-, 0.00, 0.02,-,-, 0.00,-,-, lr of zeroth group 1.4976545357900817e-05 data time  2.32 step time  0.97 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  35 | time: 387.36s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.14,-,-,-,-, 0.16,-, 0.06,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.06,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.38, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.24,-,-,-,-,-,-, 0.00, 0.11,-, 0.00,-,-,-,-,-,-,-,-, 0.01, 0.01,-, 0.25, 0.01,-,-,-,-,-,-, 0.19,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-, 0.02,-,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-, 0.01,-, 0.01, 0.01,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-, 0.03,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.27,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.74,-,-,-,-, 0.00,-,-, 0.00, 0.51,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.38,-, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.19,-, 0.08,-,-,-,-,-,-,-,-, 0.01, 0.00,-,-,-, 0.01,-, 0.01, 0.01,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-,-,-,-, 0.35,-, 0.00,-,-,-,-, 0.01, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.70,-, 0.00,-,-, 0.19,-,-,-, 0.00,-, 0.28,-, 0.00,-,-,-, 0.01, 0.00,-,-,-,-, 0.01,-, 0.02, 0.01,-,-, 0.16,-,-,-,-,-, 0.12,-,-, 0.01,-,-,-, 0.00, 0.01,-, 0.00,-,-,-,-, 0.00,-,-, 0.00,-, 0.00,-, 0.00,-, 0.00,-, 0.00, 0.00,-,-,-, 0.00,-,-, lr of zeroth group 1.3119496529610197e-05 data time  2.71 step time  0.94 forward time  0.32 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  36 | time: 387.32s | mean loss  0.05 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-, 0.08,-,-,-,-,-,-,-,-, 0.04,-,-,-, 0.17,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-,-,-, 0.01, 0.16,-,-,-, 0.01, 0.11,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.11,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.29,-,-,-,-,-,-, 0.09,-,-,-,-,-,-,-,-,-, 0.08,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.22,-,-,-,-,-,-,-, 0.13,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-, 0.28,-,-,-,-,-,-,-, 0.01,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.12,-,-,-, 0.00,-,-,-,-,-,-, 0.00, 0.00,-, 0.06, 0.00,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.58,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-, 0.00,-,-,-,-,-,-,-, 0.01,-, 0.01,-, 0.37,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-, 0.50,-, 0.03, 0.33, 0.01,-, 0.01,-,-,-, 0.21,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-, 0.00, 0.00, 0.01,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00, 0.00, 0.01,-, 0.00,-,-, 0.01, 0.01,-,-, 0.01,-, 0.00,-, 0.00,-, 0.00, 0.00,-, lr of zeroth group 1.1343603586694372e-05 data time  3.41 step time  0.61 forward time  0.21 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  37 | time: 388.64s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-, 0.17,-,-,-,-,-,-,-,-, 0.06,-,-,-,-,-,-, 0.19,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.06,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.18,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01, 0.43, 0.02,-,-,-,-,-,-,-,-, 0.26,-, 0.04,-,-,-,-,-,-,-,-,-,-,-,-, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-, 0.11,-, 0.06,-,-,-,-,-,-, 0.00,-, 0.00, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-,-, 0.14,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-, 0.25,-,-,-,-,-, 0.01, 0.00,-, 0.94,-,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-, 0.00,-,-,-,-,-, 0.04,-,-,-, 0.00,-,-,-, 0.01, 0.22,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-, 0.01, 0.13, 0.17,-, 0.01,-,-, 0.00,-, 0.01,-,-,-,-, 0.01,-,-, 0.37,-,-,-,-, 0.00,-, 0.00,-,-,-,-,-, 0.01,-,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-, 0.00,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-, 0.00,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00, 0.00,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.03, 0.00, 0.76, 0.00, 0.00, 1.29,-,-, 0.00, 0.01, 0.00,-, 0.03, 0.00,-, 0.01,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-,-,-, 0.00,-, 0.00, 0.01, 0.00,-,-, lr of zeroth group 9.660997678685216e-06 data time  2.83 step time  0.61 forward time  0.21 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  38 | time: 421.70s | mean loss  0.05 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.27,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.24,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.25,-,-, 0.01,-,-,-,-, 0.00,-, 0.24,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-, 0.26,-,-,-,-,-, 0.00,-,-, 0.10,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-, 0.01,-,-,-, 0.00, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.09,-,-,-,-,-,-,-, 0.00,-, 0.08, 0.17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.64,-,-, 0.14,-,-,-,-, 0.00, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.11,-,-,-, 0.13,-,-,-,-, 0.00, 0.00,-,-, 0.01,-,-,-, 0.01,-, 0.00, 0.00,-, 0.13, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-,-, 0.01,-, 0.00,-,-,-,-,-, 0.00, 0.78,-,-,-, 1.01, 0.00, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.27,-, 0.01,-,-,-,-,-, 0.06,-,-,-,-,-, 0.00,-,-,-,-, 0.00, 0.09,-,-,-,-,-, 0.02,-,-, 0.00,-,-,-, 0.01,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-,-,-, 0.00, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-,-,-, 0.00, 0.00,-,-,-,-,-, 0.00, 0.02,-, 0.00, 0.01,-,-,-, 0.01,-,-,-, 0.00,-, 0.01, 0.01,-, 0.00,-,-,-, lr of zeroth group 8.083172710074385e-06 data time  4.05 step time  0.84 forward time  0.29 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  39 | time: 409.03s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-, 0.08,-, 0.03,-,-,-,-, 0.00,-,-,-,-,-, 0.18,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.00,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-, 0.21,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01,-, 0.00,-, 0.01,-, 0.12,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00, 0.12, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.11,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-, 0.05,-, 0.01,-,-,-,-,-,-, 0.00,-,-,-,-, 0.19,-,-,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-, 0.01, 0.27,-,-,-, 0.01,-,-, 0.04,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.01,-,-, 0.05,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-, 0.12,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-, 0.10, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.28,-,-,-,-,-,-, 0.00, 0.22,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.17,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01, 0.15,-,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.00, 0.01,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-,-, 0.01, 0.01, 0.01,-,-,-, 0.01,-,-, 0.01,-, 0.00, 0.00,-,-,-,-,-, 0.01,-,-, 1.13,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-, 0.00,-,-,-, 0.00,-, 0.00, 0.00,-,-,-,-, 0.00,-, 0.00,-, 0.01,-,-, 0.00,-, 0.01, 0.00,-,-,-,-, 0.00,-, lr of zeroth group 6.620906825290946e-06 data time  3.14 step time  0.97 forward time  0.34 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  40 | time: 391.19s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-,-, 0.06, 0.01,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-, 0.00,-, 0.02,-,-, 0.00,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.06,-,-,-,-,-,-, 0.02,-,-,-,-,-, 0.01,-, 0.24,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-,-, 0.01, 0.07,-, 0.00,-,-,-,-,-,-,-, 0.85,-,-,-,-,-,-,-, 0.00, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-,-, 0.01,-, 0.20,-,-,-, 0.01,-,-,-,-,-, 0.18,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.14,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.09,-,-, 0.01,-, 0.27,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.15,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-, 0.70,-, 0.00,-, 0.01,-, 0.03,-, 0.01, 0.01,-, 0.18,-,-, 0.00,-,-,-,-,-,-, 0.01, 0.00,-,-,-, 0.52,-,-,-,-,-, 0.30,-,-, 0.01,-,-,-, 0.01,-, 0.00,-, 0.00,-,-, 0.00, 0.01,-,-,-,-,-, 0.00, 0.01, 0.02,-,-,-,-,-, 0.00,-, 0.00,-, 0.01,-,-,-, 0.01,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.00,-, 0.04,-,-,-,-,-,-, 0.01, 0.00,-,-,-,-, 0.00,-,-, 0.00,-,-, 0.00,-, 0.00,-,-,-, 1.93,-, 0.00,-,-, 0.00,-, 0.00, 0.00,-,-,-, 0.00,-, 0.02,-, lr of zeroth group 5.284188783046082e-06 data time  2.96 step time  0.95 forward time  0.31 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  41 | time: 390.50s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-, 0.15,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-, 0.01, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.57,-,-,-,-,-,-,-, 0.17,-,-,-, 0.14,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.44,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.00,-, 0.21,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-,-, 0.01,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.00, 0.00,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.14,-,-,-,-,-, 0.00,-,-, 0.00,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-,-, 0.41,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.09,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.00,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.62, 0.22,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.02, 0.26,-, 0.00,-,-,-, 0.01, 0.01,-,-, 0.00, 0.00,-, 0.00,-,-,-,-, 0.01,-,-, 0.01,-, 0.01,-, 0.00,-,-, 0.00, 0.00,-, 0.00,-, 0.01,-,-,-, 0.00,-, 0.01,-,-,-,-, 0.00,-, 0.01, 0.01, 0.00,-, 0.01,-, 0.00,-, 0.00,-, 0.01, 0.01,-, lr of zeroth group 4.082149722982584e-06 data time  3.59 step time  0.60 forward time  0.21 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  42 | time: 383.46s | mean loss  0.07 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.17,-,-,-,-, 0.07,-,-,-,-, 0.01,-,-,-, 0.00,-,-, 0.19,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-, 0.01,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.14,-, 0.01, 0.00,-,-,-,-,-,-,-, 0.07,-,-,-, 0.08,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-, 0.09,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.12,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.22, 0.00,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.42,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.15, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.06,-, 0.00,-, 0.01,-,-, 0.00,-,-,-, 0.00, 0.20,-,-, 0.01,-,-,-,-,-,-, 0.00,-,-,-, 0.08, 0.17, 0.00, 0.00, 0.58,-, 0.16,-,-,-,-,-,-,-,-,-, 0.00, 0.01,-, 0.01,-, 0.00,-, 0.00,-,-,-,-,-,-, 0.01, 0.00,-,-,-, 0.27,-,-, 0.02,-, 0.38,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01,-,-,-,-,-, 0.01, 0.00,-,-,-,-, 0.00,-,-, 0.00, 0.01, 0.68, 0.00,-,-, 0.28, 0.59,-, 0.00,-,-, 0.00,-, 2.82,-,-,-, 0.00,-, 0.00,-, 0.00,-, lr of zeroth group 3.0230007907322526e-06 data time  2.70 step time  0.89 forward time  0.31 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  43 | time: 393.62s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.06,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.01,-,-,-,-, 0.02,-, 0.02,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.02,-,-,-,-,-,-,-,-,-, 0.06,-, 0.02, 0.34,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.03, 0.00,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.00, 0.10,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.18, 0.00, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.25,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.21,-,-,-,-,-, 0.00,-,-,-,-,-, 0.17, 0.15,-,-,-,-,-,-, 0.10, 0.01,-,-,-,-,-,-, 0.13,-,-,-,-,-, 0.01,-,-,-,-, 0.00,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.33,-,-,-,-,-,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-,-,-,-, 0.01, 0.25,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01,-, 0.02,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-, 0.00, 0.01, 0.59, 0.01,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-, 0.04,-, 0.00,-, 0.01, 0.00,-,-, 0.00,-,-, 0.00,-,-, 0.00,-,-, 0.00,-, 0.00, 0.01,-, 0.00, 0.00, 0.01,-,-,-, 0.00,-,-, 0.00,-, 0.00, 0.00, 0.00, 0.00,-,-,-, lr of zeroth group 2.11397704746526e-06 data time  3.02 step time  0.98 forward time  0.34 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  44 | time: 394.46s | mean loss  0.07 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-, 0.12,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.39,-,-,-, 0.08,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.09,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.08,-,-,-,-,-,-,-, 0.09,-, 0.12,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.00, 0.00,-,-,-,-,-,-,-, 0.11, 0.00,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-, 0.16,-,-,-,-,-, 0.00,-, 0.70,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.00, 0.00,-,-, 0.04,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-, 0.01,-,-,-,-, 0.01,-,-,-, 0.00, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-,-, 0.01,-,-, 0.00,-,-,-, 0.23,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00, 0.01,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-, 0.01,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-, 0.01, 0.01, 0.01, 0.96, 0.00,-, 0.00, 0.00,-,-,-,-, 0.00,-,-, 0.01,-,-,-, 0.00,-, 0.00,-, 0.43, 0.00,-, 0.01,-, 0.00,-,-, 0.01,-,-,-,-, 0.00,-, 0.19, 1.39,-, 0.05,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 2.08,-, 0.00,-,-, 0.00, 0.00,-, 0.00,-,-, 0.00,-, 0.02,-, lr of zeroth group 1.361288047086051e-06 data time  3.46 step time  0.70 forward time  0.23 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  45 | time: 390.00s | mean loss  0.06 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-, 0.15,-,-,-,-,-,-,-, 0.33,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-,-,-,-, 0.06,-,-, 0.11, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.08,-,-,-,-, 0.05, 0.01,-,-,-,-,-,-,-,-,-,-, 0.11,-, 0.00,-, 0.01,-,-,-, 0.01,-,-, 0.02,-,-,-,-,-,-,-,-,-,-,-,-, 0.09, 0.03,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-, 0.14,-, 0.40, 0.01,-,-,-,-,-,-,-, 0.00,-,-, 0.30,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.20,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-, 0.02,-,-,-,-,-,-, 0.12,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.00,-, 0.28, 0.17, 0.00,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-, 0.31,-, 0.00,-,-,-,-,-,-,-, 0.02,-, 0.02, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00, 0.23,-, 0.00,-,-,-,-, 0.01,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.00,-,-,-,-, 0.73,-,-,-,-,-,-, 0.01,-,-, 0.00, 0.01,-,-,-,-,-,-, 0.01,-, 0.00,-,-, 0.01,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00, 0.00,-, 0.01,-,-, 0.00,-,-,-,-,-, 0.01,-, 0.00,-,-, 0.00, 0.00, 0.00, 0.01, 0.00, 0.00,-, lr of zeroth group 7.700754186838382e-07 data time  2.64 step time  0.68 forward time  0.23 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  46 | time: 390.55s | mean loss  0.07 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.07,-,-,-,-,-,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.00,-,-,-, 0.00,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-,-, 0.19, 0.01,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.13,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.06,-,-,-,-,-,-,-, 0.04,-, 0.44,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.20,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-, 0.18,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.24,-,-,-,-, 0.01,-, 0.07,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.27,-,-,-,-,-,-, 0.00,-,-,-,-, 0.11,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.23,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-, 0.00,-,-, 0.00,-,-,-,-, 0.01, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-, 0.00,-,-,-,-, 0.10,-,-,-,-,-,-,-, 0.00, 0.01,-,-, 0.00, 0.00,-,-,-,-,-,-,-,-,-, 0.01, 0.32, 0.00,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-, 0.00, 0.38, 0.00, 0.00,-, 0.64,-,-,-,-, 0.03,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.63,-, 0.02,-, 0.00,-,-, 0.32,-,-,-, 0.00,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-,-,-,-,-, 0.01, 0.00,-,-, 0.00,-, 1.84,-,-,-, 0.01,-,-, 0.01,-,-,-,-,-,-,-,-,-, 0.01, 0.00, 0.00, 0.00,-, 0.00,-,-, 0.00, 0.00,-,-,-,-,-, 0.00, 0.01,-, 0.01, 0.00,-,-, 0.00,-, lr of zeroth group 3.4437774399231904e-07 data time  3.48 step time  1.00 forward time  0.35 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  47 | time: 389.41s | mean loss  0.08 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-, 0.16,-,-,-,-,-, 0.11,-,-,-,-,-, 0.08,-,-, 0.10,-,-,-,-, 0.01, 0.00, 0.15,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.22,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.01,-,-,-,-,-, 0.01, 0.01,-,-,-,-, 0.05,-,-,-,-, 0.27,-,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-, 0.18, 0.01, 0.01,-, 0.01,-,-,-,-,-,-, 0.00, 0.01,-, 0.15,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.11, 0.00, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-, 0.09,-, 0.01,-,-, 0.01,-, 0.00, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00, 0.00, 0.00,-,-,-,-,-,-,-,-, 0.26,-,-, 0.14,-,-,-,-, 0.08, 0.06, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.30,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-, 0.01,-,-, 0.06,-,-,-,-,-, 0.16,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-, 0.02,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.00,-,-,-,-,-, 0.00,-,-, 0.00,-, 0.01,-,-,-,-,-, 0.42,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-,-,-, 0.00,-,-, 0.00,-,-, 0.00, 0.01,-,-,-,-, 0.00,-,-, 0.00,-, 0.01,-,-,-,-, 0.01,-, 0.01,-, 0.00,-,-, 0.00,-,-, 0.02, 0.00,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.01,-,-,-, 0.01, 0.00,-, 0.01,-,-,-, 0.00,-,-, lr of zeroth group 8.710296978139965e-08 data time  3.33 step time  0.88 forward time  0.31 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  48 | time: 387.55s | mean loss  0.05 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03,-, 0.02,-,-,-, 0.14,-,-, 0.01,-,-, 0.05,-,-,-,-,-,-,-, 0.00,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.22,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.10,-,-,-,-,-,-, 0.32,-,-,-,-, 0.04,-, 0.01,-,-,-, 0.13,-,-, 0.01,-,-,-, 0.00,-,-,-,-,-,-, 0.05,-, 0.28,-,-, 0.05,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-, 0.39,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.02,-, 0.01,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.53,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-, 0.01,-, 0.39, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.33,-,-, 0.15, 0.00,-, 0.01,-,-,-,-,-,-, 0.00,-, 0.76, 0.01,-,-,-,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-, 0.00,-, 0.01,-,-,-,-, 0.00,-, 0.01,-, 0.16,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-,-, 0.00,-, 0.00, 0.00,-, 0.31, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-, 0.01,-,-,-,-,-, 0.00,-,-,-,-, 0.01, 0.01, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.51,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-, 0.53,-,-, 0.01,-,-,-,-,-,-,-, 0.00, 0.00,-, 0.00, 0.01,-,-,-, 0.00, 0.00,-,-, 0.00, 0.00, 0.00, 0.01,-,-,-, lr of zeroth group 8.543632132318457e-12 data time  3.85 step time  0.88 forward time  0.29 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  49 | time: 387.17s | mean loss  0.05 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.01,-,-,-,-,-,-, 0.45,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.12, 0.22,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-, 0.14,-,-,-,-,-, 0.06,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.13,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.06,-, 0.02,-,-,-, 0.21,-,-,-,-, 0.01,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-, 0.09,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.45,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00, 0.00,-,-,-, 0.01,-,-, 0.26,-, 0.00,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.01, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-, 0.12,-,-,-, 0.00,-, 0.20,-,-,-, 0.01,-,-,-, 0.17,-,-,-,-,-, 0.00,-,-,-,-, 0.64,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01, 0.00, 0.00,-,-,-, 0.01,-, 0.01,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.28,-,-,-,-,-,-,-,-, 0.00, 0.01,-,-,-, 0.42,-,-, 0.00, 0.01, 0.63,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-, 0.00,-,-,-,-, 0.00, 0.00,-, 0.00,-,-, 0.00,-,-, 0.00, 0.01,-, 1.26, 0.00,-, 0.01,-,-,-, 0.00, 0.00,-,-,-,-,-, 0.00, 0.01,-,-, 0.01, 0.00,-, 0.00, 0.01, 1.82,-, 0.00, 0.00,-,-,-,-,-,-, 0.00,-, 0.01,-, 0.01,-,-, lr of zeroth group 8.36894087877016e-08 data time  2.82 step time  0.90 forward time  0.34 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  50 | time: 414.87s | mean loss  0.05 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-,-,-,-,-, 0.01,-,-, 0.00,-,-,-,-,-,-,-,-, 0.00,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 0.04,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-, 0.00,-,-,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-, 0.01, 0.33,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19, 0.25,-, 0.09,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.41,-, 0.07,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-, 0.03,-,-, 0.01,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.05,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-, 0.07,-, 0.00,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-, 0.00,-,-, 0.01,-, 0.03,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.00,-,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.68,-, 0.00,-,-, 0.00,-, 0.00, 0.01,-,-,-,-,-,-, 0.00,-,-, 0.46,-,-,-,-,-,-, 0.01,-,-,-,-,-,-,-,-,-,-,-, 0.00,-,-,-, 0.01, 0.01, 0.00,-,-, 0.00,-,-,-,-,-,-,-, 0.03,-, 0.01, 0.00, 0.00,-,-,-,-,-,-,-,-,-,-,-,-, 1.20,-,-,-,-,-, 0.00,-,-,-,-,-,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-,-, 0.00,-, 0.01,-,-,-,-, 0.00,-, 0.42,-,-,-, 0.00,-, 0.00,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.03, 0.00, 0.01,-,-,-,-, 0.00, 0.01,-, 0.00, 0.00,-,-,-,-, 0.00,-, 0.00, 0.00, 0.00, 0.00, 0.00,-, lr of zeroth group 3.3757394008781526e-07 data time  3.90 step time  0.83 forward time  0.30 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
DONE
Finished at Tue May  7 04:51:37 PM CEST 2024
