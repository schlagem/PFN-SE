Using cpu:0 device
init dist
Not using distributed
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 4, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x71e34bbe7880>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'env_name': 'MomentumEnv', 'num_hidden': 1, 'relu': False, 'sigmoid': False, 'sin': True, 'state_offset': 3.2802608490289904, 'state_scale': 18.147661409701062, 'tanh': True, 'test': False, 'use_bias': False, 'use_dropout': False, 'use_layer_norm': True, 'use_res_connection': True, 'width_hidden': 16, 'no_norm': False}}, 'get_batch_method': <function get_batch at 0x71e34bbe5f30>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized data loader with 100 steps and 4 batch size
DataLoader.__dict__ {'num_features': 14, 'num_steps': 100, 'batch_size': 1, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x71e34bbe7880>, 'seq_len_maximum': None, 'device': 'cpu:0', 'get_batch_kwargs': {'epoch_count': 0, 'hyperparameters': {'env_name': 'MomentumEnv', 'num_hidden': 1, 'relu': False, 'sigmoid': False, 'sin': True, 'state_offset': 3.2802608490289904, 'state_scale': 18.147661409701062, 'tanh': True, 'test': False, 'use_bias': False, 'use_dropout': False, 'use_layer_norm': True, 'use_res_connection': True, 'width_hidden': 16, 'no_norm': False}}, 'get_batch_method': <function get_batch at 0x71e34bbe5f30>, 'model': None, 'epoch': 0, 'test_loader': False}
Initialized decoder for standard with (None, 14)  and nout 14
Using a Transformer with 86.40 M parameters
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 742.71s | mean loss  0.38 | pos losses -,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.38,-, 0.31,-,-, 0.20,-,-,-,-,-,-, 0.36,-,-, 0.23,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.51,-, 0.21,-,-,-,-,-,-,-,-,-,-,-,-, 0.63,-,-,-,-,-,-,-, 0.29, 0.21,-,-,-,-,-,-,-,-,-,-, 0.20, 0.24,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-, 0.89, 0.31,-,-,-,-,-, 0.49,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.60,-,-,-,-,-, 0.32,-, 0.43,-,-,-,-,-,-, 0.20,-, 0.17,-,-,-, 0.29,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.22,-,-,-,-,-,-,-, 0.44,-,-,-,-,-,-,-,-, 0.45,-,-,-,-,-,-, 0.40,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-,-,-,-,-,-,-, 0.32,-,-,-,-, 0.54,-,-,-,-,-, 0.26,-,-,-,-,-,-,-, 0.47,-,-,-,-,-,-,-, 0.61,-,-, 0.35,-,-,-, 0.38,-,-, 0.50, 0.26,-,-, 0.32,-,-,-,-,-,-,-, 0.68,-,-,-,-, 0.10,-,-,-,-,-,-,-,-,-,-,-,-, 0.25, 0.96,-,-,-,-,-,-,-,-,-, 1.08,-,-,-,-,-,-, 0.31,-,-,-,-,-, 0.24,-, 0.13,-,-,-,-,-,-,-,-,-, 0.29, 0.37,-,-,-,-,-,-, 0.38, 0.25, 0.60,-,-,-,-,-, 0.36,-,-,-,-,-,-,-,-,-, 0.22,-, 0.23,-, 0.33,-,-,-,-,-,-,-,-, 0.35, 0.29,-,-,-, 0.41, 0.21, 1.13,-,-,-,-,-,-, 0.23,-,-,-, 0.16,-,-,-,-,-,-, 0.16, 0.23,-,-,-,-,-,-, 0.22,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.19,-,-,-,-, 0.31,-,-,-,-,-,-,-,-,-, 0.30,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.37,-,-, 0.52,-, 0.27,-, 0.17,-, 0.34,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-, 0.35,-,-,-, 4.32,-,-, 2.66,-,-, 0.13,-,-,-,-, 0.30,-,-, 0.32,-,-, 0.15,-,-, 0.15,-,-,-, 0.25, 0.57, 0.34,-, 0.15, 0.64, 0.31, 0.35,-, 0.15,-, 0.10, 0.40, 0.59,-,-, lr of zeroth group 1.2458333333333336e-05 data time  2.53 step time  5.13 forward time  1.78 nan share  0.00 ignore share (for classification tasks) 0.0000
-----------------------------------------------------------------------------------------
DONE
Finished at Mon May  6 11:00:45 PM CEST 2024
